{
  "tokenization_config": {
    "input_path": "data/raw/synthetic_50M.jsonl",
    "output_path": "data/tokenized/synthetic_demo",
    "tokenizer_name": "EleutherAI/gpt-neox-20b",
    "max_seq_length": 2048,
    "batch_size": 1000,
    "validation_split": 0.1,
    "max_tokens": null,
    "append_eos": true,
    "save_format": "arrow",
    "num_proc": 4,
    "resume": true
  },
  "tokenizer_info": {
    "name": "EleutherAI/gpt-neox-20b",
    "vocab_size": 50254,
    "eos_token": "<|endoftext|>",
    "eos_token_id": 0,
    "pad_token": "<|endoftext|>"
  },
  "statistics": {
    "total_documents": 2000,
    "total_tokens": 7253100,
    "total_sequences": 3542,
    "avg_doc_length": 3626.55,
    "max_doc_length": 5969,
    "min_doc_length": 1415
  },
  "dataset_info": {
    "train_samples": 3187,
    "validation_samples": 355,
    "sequence_length": 2048
  },
  "created_at": "2025-06-25T18:52:50.820435",
  "datadecider_version": "0.1.0",
  "checksums": {
    "train/data-00000-of-00001.arrow": "20ee750aacba79c6ec560d144d035e275229ae0ebedd0839f0e55950f8a28f8a",
    "validation/data-00000-of-00001.arrow": "a1063a1b55a5f0d63e7d93adecc148e38b6ffc61117963422bbb142ca2b17570"
  }
}
